Where the whale-things are? 
========================================================
css: custom.css

David L Miller (`@millerdl`)

University of Melbourne

15 April 2016 

<br/>

<small>Slides available at [http://converged.yt](http://converged.yt)</small>

```{r setup, include=FALSE}
library(knitr)
library(viridis)
opts_chunk$set(cache=TRUE, echo=FALSE)
# load the sperm whale data
load("spermwhale-analysis/df-models.RData")
```

Who is this guy?
========================================================

- Currently:
  - NOAA Northeast Fisheries Science Center (sic), Woods Hole, MA
  - ("Honourary" (ha!) position at St Andrews)
- Previously:
  - Centre for Research into Ecological and Environmental Modelling, St Andrews
  - University of Rhode Island
  - PhD Bath, UK; spatial modelling w/ Simon Wood
- Why am I here?
  - Collab w/ Mark Bravington CSIRO, Nat Kelly Antarctic Division

blah
==================
title: false


<div class="bigq">
not a real statistician,<br/>
not a real ecologist,<br/>
knows nothing about whales.
</div>

with that in mind...
=======================
type:section

(a talk)

Abundance and distribution: why?
========================================================

- Want to know where they are
  - whale watching/stock assessments
- Want to know where they aren't
  - Navy/seismic/oil/shipping/fishing etc
- Want to know what they like/dislike
  - ecology/biology


How? Big white boats
========================================================

<img src="images/bigwhiteship.png" width=100%>

How? Big white boats
========================================================

<img src="images/observers.png" width=100%>


Can't we just count them all?
==================
type:section

Detectability
=====================
type:section

blah
=====================
title:false

![](images/PaulAllor_perception_bias.png)

Distribution
=====================
type:section

Here be dragons?
=====================
title: false

<img src="images/aftt.png">

Here be dragons? 
=====================
title: false

<img src="images/aftt-pokemon.png">

Examples in this talk
========================================================
type:section

Sperm whales off the US east coast
====================================

![](images/spermwhale.png)

***

- Hang out near canyons, eat squid
- Surveys in 2004, US east coast
- Combination of data from 2 NOAA cruises
- Data used in course at Duke w/ Jason Roberts [distancesampling.org/workshops/duke-spatial-2015/](http://distancesampling.org/workshops/duke-spatial-2015/)

Example data (thanks NOAA!)
========================================================

<img src="images/data_ships.png">

Let's talk about detectability
========================================================
type:section

Detectability
========================================================

<img src="images/distance-animation.gif" width=900px>

Distance sampling
========================================================

- "Fit to the histogram"
- Model:

$$
\mathbb{P} \left[ \text{animal detected } \vert \text{ animal at distance } y\right] = g(y;\boldsymbol{\theta})
$$

- Calculate the average probability of detection:

$$
\hat{p} = \frac{1}{w} \int_0^w g(y; \boldsymbol{\hat{\theta}}) \text{d}y
$$


Distance sampling (extensions)
========================================================

  * Covariates that affect detectability (Marques et al, 2007)
  * Perception bias ($g(0)<1$) (Burt et al, 2014)
  * Availability bias (Winiarski et al, 2013; Borchers et al, 2013)
  * Detection function formulations (Miller and Thomas, 2015)
  * Measurement error (Marques, 2004)
&nbsp;
<div align="center"><img src="images/covar-df.png" width=780px></div>

<small>Figure from Marques et al (2007)</small>


Horvitz-Thompson-like estimators
========================================================

- Rescale the (flat) density and extrapolate

$$
\hat{N} = \frac{\text{study area}}{\text{survey area}}\sum_{i=1}^n \frac{s_i}{\hat{p}_i}
$$

(where $s_i$ are group/cluster sizes)


That's not really how the ocean works
==================
type:section

Model-based abundance estimation
========================================================

Rather than hoping our design detects to the changes in density and contriving a complex set of strata, use a model!

- *a priori*, no idea how "bad" your design is $\Rightarrow$ use a model.
- *a posteriori*, no idea how "bad" your design was $\Rightarrow$ use a model.

Density surface models
===============
type:section

Hedley and Buckland (2004)

Miller et al. (2013)

DSM flow diagram
==================
title:false

<img src="images/dsm-flow2.png" alt="DSM process flow diagram" width=100%>

Data setup
================================================
title:false

<img src="images/dsmproc.png">

<small>[Physeter catodon by Noah Schlottman](http://phylopic.org/image/dc76cbdb-dba5-4d8f-8cf3-809515c30dbd/)</small>



2 (or more)-stage models
===========================

- Detectability $\Rightarrow$ effective area surveyed (offset in model)
- Multi-stage models are handy!
- Understand (and **check**) each part
- Split your modelling efforts amongst people


Generalised additive models (in 1 slide)
================================================

Taking the previous example...

$$
n_j = \color{red}{A_j}\color{blue}{\hat{p}_j} \color{green}{\exp}\left[\color{grey}{ \beta_0 + \sum_k f_k(z_{kj})} \right] + \epsilon_j
$$

where $\epsilon_j \sim N(0, \sigma^2)$, $\quad n_j\sim$ count distribution

- $\color{red}{\text{area of segment}}$
- $\color{blue}{\text{probability of detection in segment}}$
- $\color{green}{\text{(inverse) link function}}$
- $\color{grey}{\text{model terms}}$



SPOILER ALERT: your model is probably just a very fancy GLM
================================================
type:section

Why GAMs are cool...
================================================
![](images/igam.jpg)
***
- Smooth terms
- Fancy smooths
- Fancy responses
- Random effects (by equivalence)
- Correlation structures
- See Wood (2006) for a handy intro

Count distributions
=====================

```{r countshist}
hist(dsm.nb.xy$data$count, xlab="Count", main="")
```
***
- Response is a count (not not always integer)
- Often, it's mostly zero (that's complicated)
- Want response distribution that deals with that
- Flexible mean-variance relationship

Tweedie distribution
=====================

```{r tweedie}
library(tweedie)
library(RColorBrewer)

# tweedie
y<-seq(0.01,5,by=0.01)
pows <- seq(1.2, 1.9, by=0.1)

fymat <- matrix(NA, length(y), length(pows))

i <- 1
for(pow in pows){
  fymat[,i] <- dtweedie( y=y, power=pow, mu=2, phi=1)
  i <- i+1
}

plot(range(y), range(fymat), type="n", ylab="Density", xlab="x", cex.lab=1.5,
     main="")

rr <- brewer.pal(8,"Dark2")

for(i in 1:ncol(fymat)){
  lines(y, fymat[,i], type="l", col=rr[i], lwd=2)
}
```
***
-  $\text{Var}\left(\text{count}\right) = \phi\mathbb{E}(\text{count})^q$
- Common distributions are sub-cases:
  - $q=1 \Rightarrow$ Poisson
  - $q=2 \Rightarrow$ Gamma
  - $q=3 \Rightarrow$ Normal
- We are interested in $1 < q < 2$ 
- (here $q = 1.2, 1.3, \ldots, 1.9$)



BREAK
==============
type:section

Silly things I've worked on lately...
=======================================
type:section

emoGG
=======

```{r emogg}
library(ggplot2)
library(emoGG)
ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) +
  geom_emoji(emoji="1f337")
```

***

- Use emojis in (gg)plots
- (Sounds silly but _actually_ quite useful!)

<br/>
<br/>
<br/>
[github.com/dill](http://github.com/dill/emoGG)

beyonce
========

```{r beyonce, fig.width=7, fig.height=6}
library(beyonce)
#ggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species)) +
ggplot(mtcars, aes(mpg, hp, color = as.factor(carb))) +
  geom_point(size = 3) +
  scale_color_manual(values = beyonce_palette(18)) +
  theme_gray()
```

```{r beyonce-p, fig.height=1}
beyonce_palette(18)
```

<small>[beyoncepalettes.tumblr.com/post/22065629518](http://beyoncepalettes.tumblr.com/post/22065629518)</small>

***

<img src="images/queenb.png" height=75%>





END OF BREAK
==============
type:section


Let's fit a model
================================================

```{r loaddat, echo=FALSE}
load("spermwhale-analysis/sperm-data.RData")
```
```{r firstdsm, echo=TRUE}
library(dsm)
dsm_env_tw <- dsm(count~s(Depth) + s(NPP) + s(SST),
                  ddf.obj=df_hr,
                  segment.data=segs, observation.data=obs,
                  family=tw(), method="REML")
```

(`method="REML"` uses REML to select wigglyness; Wood, 2011)

`dsm` is based on `mgcv` by Simon Wood

<img src="images/mgcv-inside.png" align="right">


```{r firstdsmhide, echo=FALSE}
dsm_xy_tw <- dsm(count~s(x, y), ddf.obj=df_hr,
                segment.data=segs, observation.data=obs,
                family=tw(), method="REML")
```

What do models look like?
================================================
title:false

```{r seconddsm, echo=FALSE, fig.height=11, fig.width=16}
dsm_env_tw <- dsm(count~s(Depth) + s(NPP) + s(SST),
                  ddf.obj=df_hr,
                segment.data=segs, observation.data=obs,
                family=tw(), method="REML")
opar <- par(mar=c(4, 6, 4, 2) + 0.1, cex.lab=2.5, cex.axis=2.5)
plot(dsm_env_tw, page=1, scale=0, lwd=3, shade=TRUE)
par(opar)
```

So we're done? Nope.
================================================

- Need to make smooths "wiggly enough" 
- Term selection
  - shrinkage (Marra & Wood, 2011)
  - $p$ values (Marra & Wood, 2012)
- Residuals check plots (Dunn and Smyth, 1996)


Tobler's first law of geography
==================================
type:section

"Everything is related to everything else, but near things are more related than distant things"

Tobler (1970)

Implications of Tobler's law
==============================

```{r pairrrrs, fig.width=12}
plot(segs[,c("x","y","SST","EKE","NPP","Depth")], pch=19, cex=0.4)
```

What can we do about this?
===========================

- Careful inclusion of terms
- Fit models using robust criteria (REML)
- Test for concurvity (`mgcv::concurvity`)
- Test for sensitivity (lots of models)

                

What is the "right" model?
=============================

<br/>
<br/>
<br/>
<div style="font-size:300%; text-align:center">
¯\_(ツ)_/¯
</div>



Let's talk about prediction
================================
type:section

Predictions over arbitrary areas
===================================

```{r predplot}
load("spermwhale-analysis/predgrid.RData")
predgrid$Nhat <- predict(dsm.tw.xy, predgrid)
p <- ggplot(predgrid) + 
      geom_tile(aes(x=x, y=y, fill=Nhat, width=10*1000, height=10*1000)) +
      coord_equal() +
      labs(fill="Density")+
      scale_fill_viridis()
print(p)
```
***
- Don't want to be restricted in where to predict
  - Predict within survey area
  - Extrapolate outside (with caution)
- Working on a grid of cells


Okay, but we're actually doing statistics
================================================
type:section

Variance
================================================

- Need to propagate uncertainty!
- This is **hard**, *but* can be done!
- Refit model with "extra" term

$$
n_j = A_j p_j \exp \left\{ \color{red}{\left[\frac{ \partial \log p_j(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}} \Big\vert_{\boldsymbol{\theta} = \hat{\boldsymbol{\theta}}}\right] \boldsymbol{\gamma}} + \beta_0 + \sum_k f_k(z_{jk}) \right\}
$$

- *random effect* -- fix the corresponding variance matrix $\boldsymbol{\gamma} \sim N(0,-\mathbf{H}^{-1}_\theta)$
- Bravington, Hedley & Miller (in prep)


Plotting uncertainty
================================================

```{r, vars, echo=FALSE}
predgrid$width <- predgrid$height <- 10*1000
predgrid_split <- split(predgrid, 1:nrow(predgrid))
var_map <- dsm.var.prop(dsm_xy_tw, predgrid_split, 
                               off.set=predgrid$off.set)
p <- plot(var_map, observations=FALSE, plot=FALSE) + 
      coord_equal() +
      scale_fill_viridis()
print(p)
```

***

- Maps of coefficient of variation (probably biased?)
- CV for given area (better)
- This is **hard**

Communicating uncertainty
================================================
![](images/uncanimation.gif)

***

- Are animations a good way to do this?
- 100 simulated possible distributions
- Some features (e.g. shelf, N-S gradient) stick out


Availability
================================================
type:section

Whales are never where you want them...
================================================

- We can only see whales at the surface
- What proportion of the time are they there?
  - Acoustics
  - DTAGs etc
  - Behavioural studies
- Fixed correction to $\hat{p}$
- Model via fancy Markov models (MMPP, HMM; Borchers et al, 2013)

![](images/poles_apart_gambolling.jpg)

<small>Photo from University of St Andrews Library Special Collections</small>


Conclusions
====================

- This methodology is general
  - Bears, birds, beer cans, Loch Ness monsters can all be modelled
- Models are flexible!
  - Linear things, smooth things, random effect things (and *more*)
- If you know GLMs, you can get started with DSMs
  - Mature theoretical basis, still lots to do
- Active user community, active software development


Acknowledgements
======================

- St Andrews: Eric Rexstad, Len Thomas, Louise Burt, Laura Marshall, Steve Buckland, Sharon Hedley
- Duke: Jason Roberts, Laura Mannocci
- CSIRO: Mark Bravington
- Antarctic Division: Natalie Kelly
- Funding: University of St Andrews, State of Rhode Island, US Navy, NOAA, International Whaling Commission

Resources
==============

![](images/mee-paper.png)

[distancesampling.org/R/](http://distancesampling.org/R/)

[distancesampling.org/workshops/duke-spatial-2015/](http://distancesampling.org/workshops/duke-spatial-2015/)


Thanks!
===============
type:section

Slides w/ references available at converged.yt

References
==========================

<div style="font-size:45%">
Borchers, D. L., Zucchini, W., Heide-Jørgensen, M. P., Cañadas, A., Langrock, R., Buckland, S. T., & Marques, T. A. (2013). Using hidden Markov models to deal with availability bias on line transect surveys. Biometrics, 69(3).
<br/>
Burt, M. L., Borchers, D. L., Jenkins, K. J., & Marques, T. A. (2014). Using mark-recapture distance sampling methods on line transect surveys. Methods in Ecology and Evolution, 5(11).
<br/>
Dunn, P. K., & Smyth, G. K. (1996). Randomized Quantile Residuals. Journal of Computational and Graphical Statistics, 5(3).
<br/>
Hedley, S. L., & Buckland, S. T. (2004). Spatial models for line transect sampling. Journal of Agricultural, Biological, and Environmental Statistics, 9(2).
<br/>
Marques, T. A. (2004). Predicting and correcting bias caused by measurement error in line transect sampling using multiplicative error models. Biometrics, 60(3).
<br/>
Marques, T. A., Thomas, L., Fancy, S. G., & Buckland, S. T. (2007). Improving estimates of bird density using multiple-covariate distance sampling. The Auk, 124(4).
<br/>
Marra, G., & Wood, S. N. (2011). Practical variable selection for generalized additive models. Computational Statistics and Data Analysis, 55(7). 
<br/>
Marra, G., & Wood, S. N. (2012). Coverage Properties of Confidence Intervals for Generalized Additive Model Components. Scandinavian Journal of Statistics, 39(1).
<br/>
Miller, D. L., Burt, M. L., Rexstad, E. A., & Thomas, L. (2013). Spatial models for distance sampling data: recent developments and future directions. Methods in Ecology and Evolution, 4(11).
<br/>
Miller, D. L., & Thomas, L. (2015). Mixture models for distance sampling detection functions. PLoS ONE.
<br/>
Winiarski, K. J., Miller, D. L., Paton, P. W. C., & McWilliams, S. R. (2013). Spatially explicit model of wintering common loons: conservation implications. Marine Ecology Progress Series, 492.
</div>



Handy awkward question answers
===============================
type:section

Straight lines vs. interpolation
=================================

```{r wiggles}
library(mgcv)
# hacked from the example in ?gam
set.seed(2) ## simulate some data... 
dat <- gamSim(1,n=50,dist="normal",scale=0.5, verbose=FALSE)
dat$y <- dat$f2 + rnorm(length(dat$f2), sd = sqrt(0.5))
f2 <- function(x) 0.2*x^11*(10*(1-x))^6+10*(10*x)^3*(1-x)^10-mean(dat$y)
ylim <- c(-4,6)

# fit some models
b.justright <- gam(y~s(x2),data=dat)
b.sp0 <- gam(y~s(x2, sp=0, k=50),data=dat)
b.spinf <- gam(y~s(x2),data=dat, sp=1e10)

curve(f2,0,1, col="blue", ylim=ylim)
points(dat$x2, dat$y-mean(dat$y))

```
***
- Want a line that is "close" to all the data
- Don't want interpolation -- we know there is "error"
- Balance between interpolation and "fit"

Smoothing parameter
=======================


```{r wiggles-plot, fig.width=15}
# make three plots, w. estimated smooth, truth and data on each
par(mfrow=c(1,3), cex.main=3.5, cex.lab=2)

plot(b.justright, se=FALSE, ylim=ylim, main=expression(lambda*plain("= just right")))
points(dat$x2, dat$y-mean(dat$y))
curve(f2,0,1, col="blue", add=TRUE)

plot(b.sp0, se=FALSE, ylim=ylim, main=expression(lambda*plain("=")*0))
points(dat$x2, dat$y-mean(dat$y))
curve(f2,0,1, col="blue", add=TRUE)

plot(b.spinf, se=FALSE, ylim=ylim, main=expression(lambda*plain("=")*infinity)) 
points(dat$x2, dat$y-mean(dat$y))
curve(f2,0,1, col="blue", add=TRUE)

```

Wigglyness by derivatives
==========================

```{r wigglyanim, results="hide"}
library(numDeriv)
library(animation)
f2 <- function(x) 0.2*x^11*(10*(1-x))^6+10*(10*x)^3*(1-x)^10 - mean(dat$y)

xvals <- seq(0,1,len=100)

plot_wiggly <- function(f2, xvals){

  # pre-calculate
  f2v <- f2(xvals)
  f2vg <- grad(f2,xvals)
  f2vg2 <- unlist(lapply(xvals, hessian, func=f2))
  f2vg2min <- min(f2vg2) -2
  
  # now plot
  for(i in 1:length(xvals)){
    par(mfrow=c(1,3))
    plot(xvals, f2v, type="l", main="function", ylab="f")
    points(xvals[i], f2v[i], pch=19, col="red")
    
    plot(xvals, f2vg, type="l", main="derivative", ylab="df/dx")
    points(xvals[i], f2vg[i], pch=19, col="red")
    
    plot(xvals, f2vg2, type="l", main="2nd derivative", ylab="d2f/dx2")
    points(xvals[i], f2vg2[i], pch=19, col="red")
    polygon(x=c(0,xvals[1:i], xvals[i],f2vg2min),
            y=c(f2vg2min,f2vg2[1:i],f2vg2min,f2vg2min), col = "grey")
    
    ani.pause()
  }
}

saveGIF(plot_wiggly(f2, xvals), "wiggly.gif", interval = 0.2, ani.width = 800, ani.height = 400)
```

![Animation of derivatives](wiggly.gif)

Making wigglyness matter
=========================

- Integration of derivative (squared) gives wigglyness
- Fit needs to be **penalised**
- **Penalty matrix** gives the wigglyness 
- Estimate the $\beta_k$ terms but penalise objective
  - "closeness to data" + penalty

Penalty matrix
===============

- For each $b_k$ calculate the penalty
- Penalty is a function of $\beta$
  - $\lambda \beta^\text{T}S\beta$
- $S$ calculated once
- smoothing parameter ($\lambda$) dictates influence


How wiggly are things?
========================

- We can set **basis complexity** or "size" ($k$)
  - Maximum wigglyness
- Smooths have **effective degrees of freedom** (EDF)
- EDF < $k$
- Set $k$ "large enough"















Don't throw away your residuals!
=================================
type:section


gam.check
=============

```{r echo=FALSE, results="hide"}
gam.check(dsm_xy_tw)
```


rqgam.check (Dunn and Smyth, 1996)
=============

```{r echo=FALSE}
rqgam.check(dsm_xy_tw)
```

Negative binomial
==================

```{r negbin}
y<-seq(1,12,by=1)
disps <- seq(0.001, 1, len=10)

fymat <- matrix(NA, length(y), length(disps))

i <- 1
for(disp in disps){
  fymat[,i] <- dnbinom(y, size=disp, mu=5)
  i <- i+1
}

plot(range(y), range(fymat), type="n", ylab="Density", xlab="x", cex.lab=1.5,
     main="")

rr <- brewer.pal(8,"Dark2")

for(i in 1:ncol(fymat)){
  lines(y, fymat[,i], type="l", col=rr[i], lwd=2)
}
```
***
- $\text{Var}\left(\text{count}\right) =$ $\mathbb{E}(\text{count}) + \kappa \mathbb{E}(\text{count})^2$
- Estimate $\kappa$
- Is quadratic relationship a "strong" assumption?
- Similar to Poisson: $\text{Var}\left(\text{count}\right) =\mathbb{E}(\text{count})$ 




Reproducible plots via stenography
====================================

- Encode plot code within the image
- via Rich FitzJohn's `stegasaur` package

```
# make a plot as a PNG file, but encode what generated it in the image
figuredout({plot(sample(100))}, "simpleplot.png")
# extract the information
cat(decode("simpleplot.png"))
```
